{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSF Photometry\n",
    "======\n",
    "\n",
    "We're going to try to piece together the different elements of a PSF photometry pipeline from scratch. Getting that done in one notebook means we'll have to cut some corners, but the process should be illustrative.\n",
    "\n",
    "We will start with an image that has already been processed by the Rubin pipelines, so all the calibration steps like bias subtraction, flat fielding, background subtraction, etc (together often called \"instrumental signature removal\") have been performed, and the image is ready for measurement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:42:40.357473Z",
     "iopub.status.busy": "2025-09-16T17:42:40.357066Z",
     "iopub.status.idle": "2025-09-16T17:42:43.591742Z",
     "shell.execute_reply": "2025-09-16T17:42:43.591156Z",
     "shell.execute_reply.started": "2025-09-16T17:42:40.357446Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.convolution\n",
    "\n",
    "import pandas as pd\n",
    "import lsst.daf.butler as dafButler\n",
    "\n",
    "import lsst.afw.display as afwDisplay\n",
    "afwDisplay.setDefaultBackend('firefly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T14:39:41.117340Z",
     "iopub.status.busy": "2025-09-15T14:39:41.116734Z",
     "iopub.status.idle": "2025-09-15T14:39:41.865606Z",
     "shell.execute_reply": "2025-09-15T14:39:41.865061Z",
     "shell.execute_reply.started": "2025-09-15T14:39:41.117314Z"
    }
   },
   "outputs": [],
   "source": [
    "b = dafButler.Butler(\"dp1\", collections=[\"LSSTComCam/DP1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T14:40:35.663183Z",
     "iopub.status.busy": "2025-09-15T14:40:35.662398Z",
     "iopub.status.idle": "2025-09-15T14:40:36.784848Z",
     "shell.execute_reply": "2025-09-15T14:40:36.784293Z",
     "shell.execute_reply.started": "2025-09-15T14:40:35.663157Z"
    }
   },
   "outputs": [],
   "source": [
    "exposure = b.get(\"visit_image\", dataId={\"instrument\": \"LSSTComCam\", \"detector\": 0, \"visit\": 2024110800246})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the image in a new tab. You can also open the images in ds9 if you like, for easier browsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afw_display = afwDisplay.Display(frame=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afw_display.mtv(exposure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding an example star\n",
    "\n",
    "I think a good way to work on a problem like this is to start with the core of the algorithm, working on just a single test case. After we have that working and tested, we can build out the infrastructure around it to run on the entire image.\n",
    "\n",
    "Let's display a small subset of the image, say 300x300 pixels in one corner of the image. By default, `imshow()` will scale the colorbar to the minimum and maximum pixel values, so let's also set some more reasonable limits so we can see some stars.\n",
    "\n",
    "We also need to use the `extent=` keyword argument to `imshow()` so that the labels on the X and Y axes correspond to the pixel coordinates that we've selected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:28:32.954758Z",
     "iopub.status.busy": "2025-09-16T17:28:32.954435Z",
     "iopub.status.idle": "2025-09-16T17:28:32.957688Z",
     "shell.execute_reply": "2025-09-16T17:28:32.957076Z",
     "shell.execute_reply.started": "2025-09-16T17:28:32.954737Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Replace this line if you are loading the image from a FITS file with astropy\n",
    "image_data = exposure.image.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's select a smaller region around something that looks like a good, isolated star. Remember to update the `extent` so we know which pixels we're looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we need to cut down the image one more time, this time to give us a \"cutout\" image of a single star-like object. The cutout should only be about 20x20 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "cutout = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centroiding\n",
    "\n",
    "\n",
    "Now that we have a test case to work on, let's find its position on the CCD.\n",
    "\n",
    "To do that, we're going to need two arrays: one which has the same shape as `cutout`, but where each value is the X coordinate of the pixel, and another where each value is the Y coordinate of the pixel. Numpy has a function called `meshgrid()` that will give us this; we just need to supply an iterator for the X values, and an iterator for the Y values. It looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:28:49.198253Z",
     "iopub.status.busy": "2025-09-16T17:28:49.197959Z",
     "iopub.status.idle": "2025-09-16T17:28:49.202231Z",
     "shell.execute_reply": "2025-09-16T17:28:49.201713Z",
     "shell.execute_reply.started": "2025-09-16T17:28:49.198232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xx:  [[2 3 4 5 6 7 8 9]\n",
      " [2 3 4 5 6 7 8 9]\n",
      " [2 3 4 5 6 7 8 9]\n",
      " [2 3 4 5 6 7 8 9]\n",
      " [2 3 4 5 6 7 8 9]\n",
      " [2 3 4 5 6 7 8 9]\n",
      " [2 3 4 5 6 7 8 9]\n",
      " [2 3 4 5 6 7 8 9]\n",
      " [2 3 4 5 6 7 8 9]\n",
      " [2 3 4 5 6 7 8 9]]\n",
      "yy:  [[20 20 20 20 20 20 20 20]\n",
      " [21 21 21 21 21 21 21 21]\n",
      " [22 22 22 22 22 22 22 22]\n",
      " [23 23 23 23 23 23 23 23]\n",
      " [24 24 24 24 24 24 24 24]\n",
      " [25 25 25 25 25 25 25 25]\n",
      " [26 26 26 26 26 26 26 26]\n",
      " [27 27 27 27 27 27 27 27]\n",
      " [28 28 28 28 28 28 28 28]\n",
      " [29 29 29 29 29 29 29 29]]\n"
     ]
    }
   ],
   "source": [
    "xx, yy = np.meshgrid(range(2, 10), range(20, 30))\n",
    "print(\"xx: \", xx)\n",
    "print(\"yy: \", yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the values in a column are the same in `xx`, and all the values in a row are the same in `yy`.\n",
    "\n",
    "Let's make an `xx` and `yy` with the values corresponding to the pixel coordinates in your cutout image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to compute the centroid. Let's compute it first in x: we want the weighted mean of xx, with our `cutout` image as the weights. Remember to normalize by the sum of `cutout` values. The same formula will apply for y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "x_center = \n",
    "y_center = \n",
    "\n",
    "print(x_center, y_center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the values you got make sense? Are they within the range of x and y coordinate values of the cutout? Does it roughly match where the star is? If not, are they possibly swapped, x-for-y and y-for-x? (It's very easy to get confused with the ordering of x and y indicies in Numpy, I make that mistake all the time).\n",
    "\n",
    "To double check that they all make sense, draw lines at the X and Y position of your centroid on the whole image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "plt.imshow(\n",
    "plt.axhline(\n",
    "plt.axvline(\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your lines cross on your chosen star, great! You've completed the first step of doing photometry, centroiding the object.\n",
    "\n",
    "Let's take the code you prototyped in the notebook cells, and wrap it into a nice function we can use later. When we call this function, we need to tell it about the coordinates of the image we're providing, so we'll add the `x_start` and `y_start` parameters to convey that. We don't need to know the other two corners, because we can figure that out from the size of `image_cutout`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:29:16.138711Z",
     "iopub.status.busy": "2025-09-16T17:29:16.138413Z",
     "iopub.status.idle": "2025-09-16T17:29:16.142243Z",
     "shell.execute_reply": "2025-09-16T17:29:16.141696Z",
     "shell.execute_reply.started": "2025-09-16T17:29:16.138690Z"
    }
   },
   "outputs": [],
   "source": [
    "# Answer\n",
    "def centroid(image_cutout, x_start, y_start):\n",
    "    ...\n",
    "    return (x_center, y_center)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSF Photometry\n",
    "\n",
    "\n",
    "We needed the centroid first, because we're going to use that position to place our \"PSF\" model. Since we have not yet fit a real PSF model to the sources in the image, we'll use a Gaussian as an approximation.\n",
    "\n",
    "I'll give you the function for a normalized 2D Gaussian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:29:16.885467Z",
     "iopub.status.busy": "2025-09-16T17:29:16.885192Z",
     "iopub.status.idle": "2025-09-16T17:29:16.888482Z",
     "shell.execute_reply": "2025-09-16T17:29:16.887969Z",
     "shell.execute_reply.started": "2025-09-16T17:29:16.885447Z"
    }
   },
   "outputs": [],
   "source": [
    "def gaussian2D(radius, mu):\n",
    "    return 1/(mu**2*2*np.pi)*np.exp(-0.5*((radius)/mu)**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First just make an image of an example PSF, on the same grid as the `cutout`. \n",
    "\n",
    "Note that the Gaussian is parameterized in terms of a radius, which means you will need to compute that radius from the position of every pixel in your image. `meshgrid` is again the tool for this.\n",
    "\n",
    "You can either use your `centroid()` function here, or for debugging it's fine to manually set `x_center` and `y_center` to specific values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_image = \n",
    "plt.imshow("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to be sure, we should check that the PSF image is normalized (approximately) by summing the pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "np.sum(psf_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we can compute the actual PSF flux. Remember the formula from the lecture is:\n",
    "\n",
    "\n",
    "$$ f_{\\rm ML}(x, y) = \\frac{\\sum_i \\hat{f}_i p_i(x,y)}{\\sum_i p_i^2(x, y)}$$\n",
    "\n",
    "where $\\hat{f_i}$ are your image values, and $p_i$ are are your PSF model values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "psf_flux =\n",
    "print(psf_flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check that the PSF flux you get matches (approximately) the flux you get from aperture photometry. If your cutout image is small enough that there are no other sources in it, you can just sum the cutout itself. No need to apply a more restrictive aperture for a debugging check like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "aperture_flux = \n",
    "print(aperture_flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your `psf_flux` reasonably matches your `aperture_flux`, well done! You have a working PSF photometry measurement, now it just needs to get wrapped up in a convenient function for later use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "\n",
    "# We need to pass both the centroid x and y, and the image cutout start x,y because the star\n",
    "# isn't necessarily at the very center of the cutout.\n",
    "\n",
    "def psf_flux_gaussian(image_cutout, centroid_x, centroid_y, radius, x_start, y_start):\n",
    "    ...\n",
    "    return psf_flux    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection\n",
    "\n",
    "Now that we have the core of the algorithm, we need to improve on our earlier step where we hand-picked a single source to measure. \n",
    "\n",
    "We know from the talk on object detection that we need to convolve the image with the PSF to detect sources. Of course, we don't yet know what the PSF is, so we'll guess and use a Gaussian again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the convolved image, we now need to find \"peaks\". That is, we want to find __pixels whose value is greater than all of their immediate neighbors__. That's a relatively easy way to make sure we (mostly) only try to run photometry once on each star.\n",
    "\n",
    "We are also applying a threshold; if a pixel value is below this threshold, we don't bother checking if it's a peak. That's useful \n",
    "to exclude faint background fluctuations that aren't statistically significant (below 5-sigma), or we might set the threshold higher if if we want only bright stars for PSF determination.\n",
    "\n",
    "The edges of the sensor often contain various artifacts, so you might want to exclude 5 to 10 pixels around each edge from the search.\n",
    "\n",
    "Programming note: we're going to do a python loop over all the pixels in the image. This is a really slow way to do this, and you should try to avoid loops like this as much as possible in python. We're doing it this way only because 1) it's illustrative and 2) it takes less than a minute; acceptable for a notebook, but not how we process LSST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer \n",
    "def find_peaks(image, threshold):\n",
    "    ...\n",
    "    \n",
    "    # Now that we're done appending to them, it will be easier if we turn the\n",
    "    # lists into numpy arrays.\n",
    "    return np.array(peak_x_values), np.array(peak_y_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the peak-finder, we need to create a \"detection image\" by convolving the real image with the PSF. Of course, we don't know the PSF yet, so you can substitute a guess: try a Gaussian kernel, with a 2.5 pixel width.\n",
    "\n",
    "The `%%time` \"magic\" will show us how long the convolution and peak-finding took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Answer\n",
    "\n",
    "convolved_image = \n",
    "\n",
    "peak_x_values, peak_y_values = find_peaks("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the positions of the peaks on the image, to make sure they look reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good debugging check is to look at a few cutouts centered on your newly-found detections. You can flip through a few of these by changing the value of `n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer\n",
    "\n",
    "cutout = ...\n",
    "\n",
    "plt.imshow(cutout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photometry on all objects\n",
    "\n",
    "\n",
    "You're almost finished, the only remaining task is to put together all the different pieces from above into one function that finds sources and measures their sizes and fluxes, and outputs a data table at the end.\n",
    "\n",
    "For the moment, I will tell you that the Gaussian PSF size is 2 pixels. If you have more time, there's an \"extra credit\" problem at the end of the notebook that will show you how to measure the PSF size directly, which also lets you measure object sizes in general. But try to get the PSF photometry working first before going onto that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "\n",
    "def run_photometry(image, threshold, psf_width):\n",
    "\n",
    "    # Make a detection image\n",
    "\n",
    "\n",
    "    # Find the peaks\n",
    "\n",
    "    # Loop over all of the peaks\n",
    "    #     For each peak, measure the centroid, flux, and append the flux to a list\n",
    "        \n",
    "    return pd.DataFrame({\"centroid_x\": centroids_x,\n",
    "                         \"centroid_y\": centroids_y,\n",
    "                         \"moment_x\": moments_x,\n",
    "                         \"moment_y\": moments_y,\n",
    "                         \"gaussian_flux\": fluxes})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that function all filled in, let's run it on the image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "photometry_table = run_photometry(image, 50, median_moment)\n",
    "print(photometry_table[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(photometry_table[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you get a table full of photometry? If so, great! If it's not working well, it's likely to be a problem with getting the right inputs to the different functions you're calling. You've tested all the steps separately, so they should be working. Getting the right indices on your image cutout is always a tricky part.\n",
    "\n",
    "If you have extra time, try adding an aperture photometry function to the processing.  You can plot the size (from the second moment) against flux to find what objects might be galaxies, and generate the cutout image to see if they're really galaxies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Credit: Measuring the PSF\n",
    "-----\n",
    "\n",
    "Once we have sources identified in an image, we want to identify which would be good for PSF determination, and then we want to measure their PSFs. In our case we're going to do both of these at once, we're going to measure sizes for all sources, and then use the mean size of those which we think are stars as our PSF model. In a more sophisticated pipeline, the object sizes might be used as a cut before passing to some more complicated PSF determination process.\n",
    "\n",
    "To obtain object sizes, we're going to measure the \"second moment\".\n",
    "\n",
    "This will look a lot like the centroid algorithm. The formula we want to implement is:\n",
    "\n",
    "$$I_{xx}^2 =  \\frac{\\sum_i (\\hat{f_i} (x_i - x_{\\rm center}))^2}{\\sum_i \\hat{f_i}^2} $$\n",
    "\n",
    "Let's try building it directly in the function this time; if it gives you trouble, feel free to try it out in some notebook cells directly (so you can see the intermediate variables better) before putting it back in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer\n",
    "def second_moment(image_cutout, centroid_x, centroid_y, start_x, start_y):\n",
    "    ...\n",
    "    return (x_width, y_width)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the second moment estimator on one of the cutouts you made above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_moment(cutout, 5.0, 5.0, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the results look reasonable, compared to the image of the cutout you made above? Note that this is the Gaussian width, not the full-width at half-max that is typically quoted for PSF sizes.\n",
    "\n",
    "If those look good, now we just need to run the second moment estimator over all the sources in your catalog. Our goal is to find if there's one particular size that fits lots of objects; that's likely to be our PSF size and the objects are likely to be stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "%%time\n",
    "\n",
    "# We will put the x and y moments in these lists\n",
    "moments_x = []\n",
    "moments_y = []\n",
    "\n",
    "for peak_x, peak_y in # complete\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have second moments in both X and Y directions, we should combine them into a single value as the square root of the sum of squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all went according to plan, you should have a nice histogram with a big peak at the PSF size. If it's not a big obvious peak, double check that the postage stamps that went into your second moment calculator are correct, and that the right centroid positions went into the calculator as well. \n",
    "\n",
    "From this histogram, you should either compute or estimate the PSF size, so you can plug this back into your `run_photometry()` function. You can also add the x and y sizes to the output photometry table, which would make it easier for the user to select stars or galaxies separately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
